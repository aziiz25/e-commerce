# -*- coding: utf-8 -*-
"""Copy of AI_capstone.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1gVcn51LmJ2C6OP-5bNh3pQ7bIwy_S1f5
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from nltk.tokenize import TweetTokenizer
from nltk.corpus import stopwords
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier
from sklearn import svm
from imblearn.over_sampling import RandomOverSampler
from imblearn.under_sampling import NearMiss
from imblearn.over_sampling import SMOTE
from imblearn.combine import SMOTETomek
#!pip install vaderSentiment
from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer
from scipy.sparse import hstack 
import nltk
from sklearn.tree import DecisionTreeClassifier
from sklearn.linear_model import LogisticRegression
from nltk.stem import WordNetLemmatizer
import gensim
import re
import pyLDAvis
import pyLDAvis.gensim_models as gensimvis
from gensim.models import CoherenceModel
from nltk import pos_tag
from gensim.models import LdaModel
from operator import itemgetter
import nlpaug.augmenter.word as naw
from tensorflow.keras.layers import Embedding,LSTM, Dense, Bidirectional, GRU
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.models import Sequential
from tensorflow.keras.preprocessing.text import one_hot
from tensorflow.keras import utils


"""data preprocessing """

df = pd.read_csv('train_data.csv')
df.sample(10)

df_test = pd.read_csv('test_data_hidden.csv')
df_test.sample()

df_test.describe()

df_test.info()

df.info()

df.describe()

df['sentiment'].value_counts().plot(kind = 'bar')
plt.show()

df_test['sentiment'].value_counts().plot(kind = 'bar')
plt.show()

df[df.duplicated()].count()

df_test[df.duplicated()].count()

df_test.drop_duplicates(inplace = True)
df_test.info()

df.drop_duplicates(inplace = True)
df.info()

df['brand'].value_counts()

df['categories'].value_counts()

df['primaryCategories'].value_counts()

df['reviews.date']

df['reviews.title']

#based on the above i see that some columns will not be needed 
df_updated = df[['reviews.text', 'sentiment']].copy()
df_test_updated = df_test[['reviews.text', 'sentiment']].copy()

df_updated.info()

df_test_updated.info()

df_updated.sample(10)

df_updated['reviews.text'] = df_updated['reviews.text'].apply(str.lower)
df_updated['reviews.text'] = df_updated['reviews.text'].str.replace('[^a-zA-Z\s]', ' ',regex=True) 
df_updated.sample(10)

df_test_updated['reviews.text'] = df_test_updated['reviews.text'].apply(str.lower)
df_test_updated['reviews.text'] = df_test_updated['reviews.text'].str.replace('[^a-zA-Z\s]', ' ',regex=True) 
df_test_updated.sample(10)

df_updated.columns = ['text', 'sentiment']
df_test_updated.columns = ['text', 'sentiment']

tweet_tokenizer = TweetTokenizer()

df_updated['text'] = [tweet_tokenizer.tokenize(text) for text in df_updated['text']]
df_updated.sample(10)

df_test_updated['text'] = [tweet_tokenizer.tokenize(text) for text in df_test_updated['text']]
df_updated.sample(10)

lem = WordNetLemmatizer()

df_updated['lemmatize_text'] = [[lem.lemmatize(word) for word in text ] for text in df_updated['text']]
df_updated.sample(10)

df_test_updated['lemmatize_text'] = [[lem.lemmatize(word) for word in text ] for text in df_test_updated['text']]
df_test_updated.sample(10)

stop_words = stopwords.words('english')

df_updated['lemmatize_text'] = [[word for word in text if word not in stop_words] for text in df_updated['lemmatize_text']]
df_updated.sample(10)

df_test_updated['lemmatize_text'] = [[word for word in text if word not in stop_words] for text in df_test_updated['lemmatize_text']]
df_test_updated.sample(10)

df_updated['updated_text'] = [' '.join(text) for text in df_updated['lemmatize_text']]
df_updated['text'] = [' '.join(text) for text in df_updated['text']]
df_updated.sample(10)

df_test_updated['updated_text'] = [' '.join(text) for text in df_test_updated['lemmatize_text']]
df_test_updated['text'] = [' '.join(text) for text in df_test_updated['text']]
df_test_updated.sample(10)

df_updated['review_length'] = [len(review) for review in df_updated['updated_text']]
df_updated.sample(10)

df_test_updated['review_length'] = [len(review) for review in df_test_updated['updated_text']]
df_test_updated.sample(10)

df_updated['sentiment'] = df_updated['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive':2})
df_updated.sample(10)

df_test_updated['sentiment'] = df_test_updated['sentiment'].map({'Negative': 0, 'Neutral': 1, 'Positive':2})
df_test_updated.sample(10)

X_train = df_updated[['updated_text']]
y_train = df_updated['sentiment']
X_test = df_test_updated[['updated_text']]
y_test = df_test_updated['sentiment']

text_vect = TfidfVectorizer()
text_vect.fit(X_train['updated_text'])
X_train_transform = text_vect.transform(X_train['updated_text'])
X_test_transform = text_vect.transform(X_test['updated_text'])

"""- apply ML algorithms without handling class imbalance"""

def model_training(model, X_train = X_train_transform, y_train = y_train, X_test = X_test_transform):
    model.fit(X_train, y_train)
    return model.predict(X_test)

def model_score(y_pred):
    return [confusion_matrix(y_test, y_pred), classification_report(y_test, y_pred, output_dict = True)]

def test(X_train = X_train_transform, y_train = y_train, X_test = X_test_transform, nb_test = True):
    result = []
    if nb_test:
      result.append(model_score(model_training(MultinomialNB(**nb_params),X_train,y_train,X_test)))

    result.append(model_score(model_training(RandomForestClassifier(**rf_params),X_train,y_train,X_test)))
    result.append(model_score(model_training(XGBClassifier(**XGB_params),X_train,y_train,X_test)))
    result.append(model_score(model_training(svm.SVC(**svc_params),X_train,y_train,X_test)))
    result.append(model_score(model_training(DecisionTreeClassifier(**dt_params),X_train,y_train,X_test)))
    result.append(model_score(model_training(LogisticRegression(**lr),X_train,y_train,X_test)))
    return result

nb_params = {
    'class_prior': [0.9 , 0.70, 0.14]
}

rf_params = {
    'max_depth':20,
     'n_estimators': 500,
     'class_weight': 'balanced'
}
XGB_params = {
    'objective': 'multi:softmax',
    'max_depth': 30,
    'learning_rate': 0.01,
    'silent': True,
    'n_estimators': 1000,
    'early_stopping_round':10,
    'num_class':3,
}

svc_params = {
    'class_weight': 'balanced'
}
dt_params = {
    
}

lr = {
    'solver':'lbfgs',
    'max_iter':50000, 
    'multi_class':'ovr'
}
result = test()

def plot_result():
  #sns.heatmap(pd.DataFrame(result[0][0]).iloc[:-1, :].T, annot=True)
  sns.heatmap(pd.DataFrame(result[0][1]).iloc[:-1, :].T, annot=True)

plot_result()

"""- feature eng add sentiment score """

analyzer = SentimentIntensityAnalyzer()
df_updated['score']= [analyzer.polarity_scores(text)['compound'] for text in df_updated['updated_text']]
df_test_updated['score']= [analyzer.polarity_scores(text)['compound'] for text in df_test_updated['updated_text']]

X_train = df_updated[['updated_text', 'score']]
y_train = df_updated['sentiment']
X_test = df_test_updated[['updated_text', 'score']]
y_test = df_test_updated['sentiment']

#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)

text_vect = TfidfVectorizer()
text_vect.fit(X_train['updated_text'])
X_train_transform = text_vect.transform(X_train['updated_text'])
X_test_transform = text_vect.transform(X_test['updated_text'])

X_train_transform_sent_score = hstack([X_train_transform, X_train['score'].values.reshape(-1, 1)])
X_test_transform_sent_score = hstack([X_test_transform, X_test['score'].values.reshape(-1, 1)])

result = test(X_train_transform_sent_score,y_train ,X_test_transform_sent_score, nb_test = False)

plot_result()

"""- Apply oversampling"""


ros = RandomOverSampler(random_state=1)

X_res, y_res = ros.fit_resample(X_train_transform, y_train)

result = test(X_res,y_res,X_test_transform)

plot_result()

text_vect = TfidfVectorizer()
text_vect.fit(X_train['updated_text'])
X_train_transform = text_vect.transform(X_train['updated_text'])
X_test_transform = text_vect.transform(X_test['updated_text'])

oversample = SMOTE()
X_train_transform_smote, y_train_smote = oversample.fit_resample(X_train_transform, y_train)

X_train_transform_smote.shape,y_train_smote.shape

nb_params = {
    'class_prior':[0.09,0.1,0.09]
}

dt_params = {
}

result = test(X_train_transform_smote, y_train_smote, X_test_transform)

plot_result()

"""- apply text augmentation"""

X_train = df_updated[['updated_text']]
y_train = df_updated['sentiment']
X_test = df_test_updated[['updated_text']]
y_test = df_test_updated['sentiment']
#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)

aug_w2v = naw.ContextualWordEmbsAug(model_path='bert-base-uncased', action="insert", device = 'cuda')

def augment_text(train,samples=1000,target = 0):
    df_n=train[train['sentiment'] == target].reset_index(drop=True)
    new_text = []
    for i in np.random.randint(0,len(df_n),samples):        
        text = df_n.iloc[i]['text']
        augmented_text = aug_w2v.augment(text)
        new_text.append(augmented_text)
    new=pd.DataFrame({'text':new_text,'sentiment':target})
    train = train.append(new).reset_index(drop=True)
    return train

df_test = df_updated[['text', 'sentiment']].copy()
#df_test['sentiment'] = y_train
df_test.sample()

df_test = augment_text(df_test,samples=1000 ,target = 1)
df_test = augment_text(df_test,samples=1000 ,target = 0)

df_test['aug_text'] = [tweet_tokenizer.tokenize(text) for text in df_test['text']]
df_test['aug_text'] = [[lem.lemmatize(word) for word in text ] for text in df_test['aug_text']]
df_test['aug_text'] = [[word for word in text if word not in stop_words] for text in df_test['aug_text']]
df_test.sample(10)

df_test['updated_text'] = [' '.join(text) for text in df_test['aug_text']]
df_test.sample(10)

vect_aug = TfidfVectorizer()
vect_aug.fit(df_test['updated_text'])

X_train_aug = df_test['updated_text']
y_train_aug = df_test['sentiment']
X_train_transform_aug = vect_aug.transform(X_train_aug)
X_test_transform_aug = vect_aug.transform(X_test['updated_text'])

rf_params = {
    'max_depth':20,
     'n_estimators': 500,
     'class_weight': 'balanced'
}

nb_params = {
    'class_prior': [0.3,0.315,0.2]
}


result = test(X_train_transform_aug,y_train_aug ,X_test_transform_aug)

plot_result()

df_test['score']= [analyzer.polarity_scores(text)['compound'] for text in df_test['updated_text']]
X_test['score'] = [analyzer.polarity_scores(text)['compound'] for text in X_test['updated_text']]
df_test[df_test['sentiment'] == 0].sample(10)

X_train_transform_aug_score = hstack([X_train_transform_aug, df_test['score'].values.reshape(-1, 1)])
X_test_transform_score = hstack([X_test_transform_aug, X_test['score'].values.reshape(-1, 1)])

svc_params = {
    'class_weight': 'balanced'
}
dt_params = {
    'class_weight': 'balanced'
}
resutl = test( X_train_transform_aug_score, y_train_aug, X_test_transform_score, nb_test = False)

plot_result()

"""- Apply under sampling after text aug"""

undersample = NearMiss()
X_train_transform_near_miss, y_train_near_miss = undersample.fit_resample(X_train_transform_aug, y_train_aug)

X_train_transform_near_miss.shape,y_train_near_miss.shape

rf_params = {
    'max_depth':20,
     'n_estimators': 500,
     'class_weight': 'balanced'
}

nb_params = {
    'class_prior':[0.09,0.1,0.09]
}

dt_params = {
}

result = test(X_train_transform_near_miss, y_train_near_miss, X_test_transform_aug)

plot_result()

combinesample = SMOTETomek()
X_train_transform_smote_tomek, y_train_smote_tomek = combinesample.fit_resample(X_train_transform_aug, y_train_aug)

X_train_transform_smote_tomek.shape,y_train_smote_tomek.shape

nb_params = {
}

result = test(X_train_transform_smote_tomek, y_train_smote_tomek, X_test_transform_aug)

plot_result()


y_train = utils.to_categorical(y_train)
y_test = utils.to_categorical(y_test)
y_train.shape

voc_size=10000
dim = 90
onehot_train=[one_hot(words,voc_size) for words in X_train['updated_text']] 
print(onehot_train[:3])

sent_length=df_updated['review_length'].max()
embedded_docs=pad_sequences(onehot_train,padding='pre',maxlen=sent_length)
print(embedded_docs[:3])

onehot_test = [one_hot(words,voc_size) for words in X_test['updated_text']]
embedded_docs_test =pad_sequences(onehot_test,padding='pre',maxlen=sent_length)
print(embedded_docs[:3])

def lstm_test():
  model = Sequential()
  model.add(Embedding(voc_size, dim, input_length= sent_length))
  model.add(Bidirectional(LSTM(150)))
  model.add(Dense(64,activation='relu'))
  model.add(Dense(3,activation='softmax'))
  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
  model.summary()
  return model

model = lstm_test()
X_train_final = np.array(embedded_docs)
X_test_final = np.array(embedded_docs_test)
history = model.fit(X_train_final, y_train, validation_data = (X_test_final, y_test) , epochs = 6 , batch_size = 64)

def model_detail(y_pred, y_test_result):
    with plt.style.context('dark_background'):
        cm = confusion_matrix(y_test_result, y_pred)
        f = sns.heatmap(cm, annot=True, fmt='d')
        f.set_title("confusion_matrix" , color = "white")
        plt.xlabel("Predicted label " , color = "white")
        plt.ylabel("True label " , color = "white")
        plt.show()
    print(classification_report(y_test_result,y_pred))

def model_result():
    #Confution Matrix and Classification Report
    Y_pred = model.predict(X_test_final)
    y_pred = np.argmax(Y_pred, axis=1)
    y_test_result = np.argmax(y_test, axis=1)
    print('Classification Report')
    target_names = [str(i) for i in range(0,3)]
    print(classification_report(y_test_result, y_pred, target_names=target_names))

    with plt.style.context('dark_background'):
        # summarize history for accuracy
        plt.plot(history.history['accuracy'])
        plt.plot(history.history['val_accuracy'])
        plt.title('model accuracy')
        plt.ylabel('accuracy')
        plt.xlabel('epoch')
        plt.legend(['train', 'test'], loc='upper left')
        plt.show()
        # summarize history for loss
        plt.plot(history.history['loss'])
        plt.plot(history.history['val_loss'])
        plt.title('model loss')
        plt.ylabel('loss')
        plt.xlabel('epoch')
        plt.legend(['train', 'test'], loc='upper left')
        plt.show()
    model_detail(y_pred,y_test_result)

model_result()

def GRU_test():
  model = Sequential()
  model.add(Embedding(voc_size, dim, input_length= sent_length))
  model.add(Bidirectional(GRU(150)))
  model.add(Dense(64,activation='relu'))
  model.add(Dense(3,activation='softmax'))
  model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])
  model.summary()
  return model

model = GRU_test()
history = model.fit(X_train_final, y_train, validation_data = (X_test_final, y_test) , epochs = 6 , batch_size = 64)

model_result()

y_train_aug = utils.to_categorical(y_train_aug)
y_train.shape

onehot_train=[one_hot(words,voc_size) for words in X_train_aug]

sent_length=df_updated['review_length'].max()
embedded_docs=pad_sequences(onehot_train,padding='pre',maxlen=sent_length)

onehot_test = [one_hot(words,voc_size) for words in X_test['updated_text']]
embedded_docs_test =pad_sequences(onehot_test,padding='pre',maxlen=sent_length)

X_train_final = np.array(embedded_docs)
X_test_final = np.array(embedded_docs_test)

model = lstm_test()

history = model.fit(X_train_final, y_train_aug, validation_data = (X_test_final, y_test) , epochs = 3 , batch_size = 64)

model_result()

model = GRU_test()
history = model.fit(X_train_final, y_train_aug, validation_data = (X_test_final, y_test) , epochs = 1 , batch_size = 64)

model_result()

"""- Topic Modeling"""



pd.set_option('display.max_colwidth' , 200)

review_df1 = pd.read_csv('train_data.csv')
review_df2 =  pd.read_csv('test_data.csv')
review_df3 =  pd.read_csv('test_data_hidden.csv')
merge = pd.concat([review_df1,review_df2,review_df3])
reviews_df = merge[['reviews.text']].copy()
reviews_df.sample(10)

reviews_df['review_length'] = [len(review) for review in reviews_df['reviews.text']]
reviews_df.sample(10)
reviews_df[reviews_df.duplicated()].count()
reviews_df.drop_duplicates(inplace = True)
reviews_df.sample(10)
plt.boxplot(reviews_df.review_length)
plt.show()
reviews_df.columns= ['review' , 'review_length']
reviews_df.sample(10)

reviews_df.review = reviews_df.review.apply(str.lower)
reviews_df.review = reviews_df.review.str.replace(r'[^a-zA-Z\s]', ' ',regex=True) 
reviews_df.review = reviews_df.review.str.replace(r'\s{2,}', ' ',regex=True)

reviews= reviews_df.review.to_list()
reviews[0]
len(reviews)



tweet_tokenizer = TweetTokenizer()
review_tokens = [tweet_tokenizer.tokenize(text) for text in reviews]
review_tokens[:2]
len(review_tokens)
reviews_with_one_word = [i for i in review_tokens if len(i) == 1]
reviews_with_one_word[:5]

len(reviews_with_one_word)

for i in reviews_with_one_word:
    review_tokens.remove(i)

review_pos  = [pos_tag(text) for text in review_tokens]
review_pos[:4]

nouns = []
for text in review_pos:
    temp = []
    for noun in text:
        if re.match('N[NP].*', noun[1]):
            temp.append(noun)
    nouns.append(temp)
nouns[:3]


lem = WordNetLemmatizer()
root_tokens = []
for words in nouns:
    temp = []
    for token in words:
        temp.append(lem.lemmatize(token[0]))
    root_tokens.append(temp)

root_tokens[:3]

stop_words = stopwords.words('english')
clean_data = []
for noun in nouns:
    temp =[]
    for token in noun:
        if token[0] not in stop_words and len(token[0]) >=4 and token[0].isalpha():
            temp.append(token[0])
    if len(temp) != 0:
        clean_data.append(temp)

clean_data[:2]


id2word = gensim.corpora.Dictionary(clean_data)


corpus = [id2word.doc2bow(text) for text in clean_data]


corpus[:2]


def calculate_topic_cv(topic_range):
  cv_score =[]
  topic_num = []
  for i in range(2,topic_range):
    topic_num.append(i)
    ldamodel = LdaModel(corpus = corpus, num_topics= i, id2word= id2word, passes= 10, random_state= 2)
    cv_score.append(CoherenceModel(model=ldamodel,texts=clean_data, dictionary=id2word , coherence='c_v').get_coherence())
    print('topic {i}: {cv}'.format(i = i, cv = cv_score[i-2]))
  return topic_num,cv_score

topic_num,cv_score = calculate_topic_cv(8)

topic_num,cv_score

num_of_topics = 4

lda = LdaModel(corpus = corpus, num_topics= num_of_topics, id2word= id2word, passes= 10, random_state=2)


print('LDA model')
for idx in range(num_of_topics):
    print('Topic #%s:'%idx , lda.print_topic(idx,12))

coherence_lda_model = CoherenceModel(model= lda,texts= clean_data, dictionary= id2word, coherence = 'c_v')


print('coherence score: ', coherence_lda_model.get_coherence())

pyLDAvis.enable_notebook()
vis = gensimvis.prepare(lda, corpus, id2word)
pyLDAvis.save_html(vis, 'lda6.html')
vis


lda_topics= lda.show_topics(formatted=False)

topics_only = []
for topic in lda_topics:
    temp_str  = ''
    for sub_topic in topic[1]:
        temp.append(sub_topic[0])
        temp_str += sub_topic[0] + ', '
    topics_only.append([topic[0] ,temp_str])

topics_only

topics_df = pd.DataFrame(topics_only, columns = ['Topic Number','Topic top words'])
topics_df['Topic name'] = ['alexa', 'kindle', 'sound quality of a product maybe alexa','tablet or ipad presented as a gift']


for sent in lda[corpus]:
  print(sent)

final_review = pd.DataFrame([', '.join(sent) for sent in clean_data], columns = ['Review keywords'])

topic_number = []
for sent in lda[corpus]:
  temp = []
  other = []
  for topic_num in sent:
    if topic_num[1] >= 0.35:
      temp.append(topic_num[0])
  if(len(temp) >= 1):
    topic_number.append(temp)
  else:
    topic_number.append([max(sent,key=itemgetter(1))[0]])
topic_number

final_review['Topic Number'] = [', '.join(map(str,number)) for number in topic_number]
final_review

#final_review.columns = ['Topic name']
topic_names = []
for topic_num in topic_number:
    temp = []
    for i in topic_num:
        temp.append(topics_df.iloc[i]['Topic name'])
    topic_names.append(', '.join(temp))
final_review['Topic name'] = topic_names

final_review

colors=['#F3C00D','#F3FA8E','#98D66B','#98D66B','#D65330','#D65330','#55E690','#55E690',
        '#4F242D', '#4F242D','#36C3F9','#36C3F9','#F31482','#F31482',
        '#3148F0','#3148F0','#577210','#577210','#C3CE4C','#C3CE4C',
        '#05F52D', '#05F52D', '#7A750B', '#7A750B', '#A7AAE7', '#A7AAE7',
        '#8CF84B', '#8CF84B', '#775412', '#775412', '#093B81', '#093B81', '#16A9D6', 
        '#16A9D6', '#DAC83C', '#DAC83C', '#EF4B9D', '#EF4B9D', '#D72E5B', '#D72E5B']
        
final_review['Topic name'].value_counts()[:6]

with plt.style.context('dark_background'):
    plt.grid(color='w', linestyle='solid') 
    plt.ticklabel_format(useOffset = False,style='plain')
    plt.style.use('classic')
    final_review['Topic name'].value_counts()[:6].plot(
        kind ='bar',figsize=(16,9), xlabel= 'Topics',
        ylabel= 'amount in each topic', color= colors,title='Show top 6 topics')
    plt.show()











